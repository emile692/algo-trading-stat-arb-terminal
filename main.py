import numpy as np
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from pathlib import Path
import itertools
import plotly.express as px

from config.params import lookback_mapping
from utils.backtest import backtest_pair, compute_metrics, walk_forward_beta_spread_zscore, walk_forward_segments, \
    compute_segment_metrics
from utils.loader import load_price_csv
from utils.metrics import (
    compute_hedge_ratio,
    compute_spread,
    compute_adf,
    compute_corr,
    compute_coint,
    compute_zscore,
    compute_half_life,
)
from utils.optimization import run_full_optimization
from utils.synthetic import (
    generate_synthetic_paths,
    generate_ou_paths,
    calibrate_params_from_pair,
    simulate_cointegrated_assets,
)

from utils.monthly_backtest import StrategyParams, BatchConfig, run_monthly_batch
from utils.global_backtest import run_global_walkforward

PROJECT_PATH = Path(__file__).resolve().parents[0]
BASE_DATA_PATH = PROJECT_PATH / "data" / "raw"
SCANNER_DATA_PATH = BASE_DATA_PATH / "d1"
DATA_PATH = PROJECT_PATH / "data" / "raw" / "d1"

# ============================================================
# PAGE CONFIG
# ============================================================
st.set_page_config(page_title="StatArb Terminal", layout="wide")
st.set_page_config(page_title="StatArb Terminal", layout="wide")


# Tous les tickers disponibles
def list_assets(base_path: Path) -> list[str]:
    p = base_path / "d1"
    if not p.exists():
        return []
    return sorted(f.stem.upper() for f in p.glob("*.csv"))


raw_data_list = list_assets(BASE_DATA_PATH)


# ============================================================
# Cache CSV loading
# ============================================================
@st.cache_data
def cached_load_price(asset: str, data_path: Path) -> pd.DataFrame:
    return load_price_csv(asset, data_path)


@st.cache_data
def load_monthly_universe() -> pd.DataFrame:
    """Load the monthly universe generated by scripts/build_monthly_universe.py."""
    path = PROJECT_PATH / "data" / "universe" / "monthly_universe.parquet"
    if not path.exists():
        return pd.DataFrame()
    df = pd.read_parquet(path)
    if "trade_start" in df.columns:
        df["trade_start"] = pd.to_datetime(df["trade_start"])
    if "trade_end" in df.columns:
        df["trade_end"] = pd.to_datetime(df["trade_end"])
    if "scan_date" in df.columns:
        df["scan_date"] = pd.to_datetime(df["scan_date"])
    return df


# ============================================================
# Session state defaults (pour le bouton Load)
# ============================================================
if "asset1" not in st.session_state:
    st.session_state["asset1"] = raw_data_list[0]

if "asset2" not in st.session_state:
    st.session_state["asset2"] = raw_data_list[1]

if "go_to_monitor" not in st.session_state:
    st.session_state["go_to_monitor"] = False

# ============================================================
# SIDEBAR
# ============================================================
with st.sidebar:
    st.header("Settings")

    source = st.selectbox("Data Source", ["FMP", "Yahoo", "Binance"])

    # Valeurs par d√©faut bas√©es sur session_state
    asset1 = st.selectbox("Asset 1", raw_data_list,
                          index=raw_data_list.index(st.session_state["asset1"]))
    asset2 = st.selectbox("Asset 2", raw_data_list,
                          index=raw_data_list.index(st.session_state["asset2"]))

    timeframe = st.selectbox("Timeframe", ["Daily", "Hourly"])

    lookback = st.selectbox("Lookback", list(lookback_mapping.keys()))
    lb = lookback_mapping[lookback]

# ============================================================
# TABS
# ============================================================
tab_monitor, tab_scanner, tab_universe, tab_mbt, tab_global, tab_backtest, tab_opt, tab_pf = st.tabs([
    "Pair Monitor", "Scanner", "Monthly Universe", "Monthly Backtest", "Backtest Global (WF)", "Backtest Pair",
    "Optimization", "Portfolio"
])

# ============================================================
# TAB 1 : PAIR MONITOR
# ============================================================
with tab_monitor:
    st.subheader("Pair Monitor")

    if st.session_state.get("go_to_monitor", False):
        st.info(
            f"Loaded pair: {st.session_state['asset1']} / {st.session_state['asset2']}",
            icon="üìà"
        )
        st.session_state["go_to_monitor"] = False

    with st.spinner("Loading data & computing metrics..."):

        # Load data
        data_path = BASE_DATA_PATH / ("d1" if timeframe == "Daily" else "h1")

        df1 = cached_load_price(asset1, data_path)
        df2 = cached_load_price(asset2, data_path)

        df1 = df1.iloc[-lb:].copy()
        df2 = df2.iloc[-lb:].copy()

        # Log-prices
        df1["log"] = np.log(df1["close"])
        df2["log"] = np.log(df2["close"])

        df1["norm"] = df1["log"] - df1["log"].iloc[0]
        df2["norm"] = df2["log"] - df2["log"].iloc[0]

        df1["logret"] = df1["log"].diff()
        df2["logret"] = df2["log"].diff()

        merged = pd.merge(
            df1[["datetime", "norm", "logret"]],
            df2[["datetime", "norm", "logret"]],
            on="datetime",
            how="inner",
            suffixes=(f"_{asset1}", f"_{asset2}"),
        )

        series_y = merged[f"norm_{asset1}"]
        series_x = merged[f"norm_{asset2}"]

        beta = compute_hedge_ratio(series_y, series_x)
        spread = compute_spread(series_y, series_x, beta)
        adf_t, adf_p, _ = compute_adf(spread)
        corr = compute_corr(series_y, series_x)
        eg_t, eg_p, _ = compute_coint(series_y, series_x)
        half_life = compute_half_life(spread)

        # Param√®tres OU
        if half_life and half_life > 0:
            theta_ou = np.log(2) / half_life
        else:
            theta_ou = 0

        mu_ou = float(spread.mean())
        sigma_ou = float(pd.Series(spread, dtype=float).diff().std(ddof=0))
        s0_ou = float(pd.Series(spread, dtype=float).iloc[-1])

        # Stockage pour l'onglet Synthetic Paths
        st.session_state["ou_mu"] = mu_ou
        st.session_state["ou_theta"] = theta_ou
        st.session_state["ou_sigma"] = sigma_ou
        st.session_state["ou_s0"] = s0_ou

        merged["spread"] = spread
        merged["zscore"] = compute_zscore(spread, window=30)
        merged["rolling_corr"] = series_y.rolling(200).corr(series_x)

        merged["cumret_y"] = np.exp(merged[f"logret_{asset1}"].fillna(0).cumsum()) - 1
        merged["cumret_x"] = np.exp(merged[f"logret_{asset2}"].fillna(0).cumsum()) - 1

    # METRICS
    col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
    col1.metric("Hedge Ratio", f"{beta:.3f}")
    col2.metric("ADF t-stat", f"{adf_t:.3f}")
    col3.metric("ADF p-value", f"{adf_p:.4f}")
    col4.metric("Correlation", f"{corr:.3f}")
    col5.metric("Stationarity?", "Yes" if adf_p < 0.05 else "No")
    col6.metric("Cointegrated?", "Yes" if eg_p < 0.05 else "No")
    col7.metric("Half-life", "N/A" if half_life is None else f"{half_life:.1f} bars")

    # =========================
    #  FIGURES (VERSION PRO)
    # =========================

    # --- Styling global ---
    default_layout = dict(
        height=250,
        template="plotly_dark",
        margin=dict(l=5, r=5, t=5, b=5),
        plot_bgcolor="rgba(0,0,0,0)",
        paper_bgcolor="rgba(0,0,0,0)",
        font=dict(size=12),
    )

    # ========== RETURNS ==========
    fig_returns = go.Figure()
    fig_returns.add_scatter(
        x=merged["datetime"], y=merged["cumret_y"],
        name=f"{asset1} cumret", line=dict(width=2)
    )
    fig_returns.add_scatter(
        x=merged["datetime"], y=merged["cumret_x"],
        name=f"{asset2} cumret", line=dict(width=2)
    )
    fig_returns.update_layout(**default_layout)

    # ========== SPREAD ==========
    # Couleurs dynamiques
    spread_pos = merged["spread"].where(merged["spread"] >= 0)
    spread_neg = merged["spread"].where(merged["spread"] < 0)

    fig_spread = go.Figure()

    # Spread positif
    fig_spread.add_scatter(
        x=merged["datetime"], y=spread_pos,
        mode="lines",
        name="Spread +",
        line=dict(color="#00cc96", width=2),
    )
    fig_spread.add_scatter(
        x=merged["datetime"], y=spread_pos,
        fill="tozeroy",
        mode="none",
        fillcolor="rgba(0,204,150,0.15)",
        showlegend=False,
    )

    # Spread n√©gatif
    fig_spread.add_scatter(
        x=merged["datetime"], y=spread_neg,
        mode="lines",
        name="Spread -",
        line=dict(color="#ff4d4d", width=2),
    )
    fig_spread.add_scatter(
        x=merged["datetime"], y=spread_neg,
        fill="tozeroy",
        mode="none",
        fillcolor="rgba(255,77,77,0.15)",
        showlegend=False,
    )

    # Ligne 0
    fig_spread.add_hline(y=0, line_color="white", opacity=0.3)

    fig_spread.update_layout(**default_layout)

    # ========== Z-SCORE ==========
    fig_z = go.Figure()
    fig_z.add_scatter(
        x=merged["datetime"], y=merged["zscore"],
        mode="lines", name="Z-score",
        line=dict(width=2, color="#1f77b4")
    )
    fig_z.add_hline(y=2, line_dash="dot", line_color="red")
    fig_z.add_hline(y=-2, line_dash="dot", line_color="green")
    fig_z.update_layout(**default_layout)

    # ========== ROLLING CORR ==========
    fig_corr = go.Figure()
    fig_corr.add_scatter(
        x=merged["datetime"], y=merged["rolling_corr"],
        mode="lines", name="Rolling Corr",
        line=dict(width=2, color="#ab63fa")
    )
    fig_corr.update_layout(**default_layout)

    # ========== SCATTER + OLS ==========
    fig_scatter = go.Figure()
    fig_scatter.add_scatter(
        x=series_x, y=series_y,
        mode="markers",
        name="points",
        marker=dict(size=5)
    )

    x_line = np.linspace(series_x.min(), series_x.max(), 100)
    y_line = beta * x_line + (series_y.mean() - beta * series_x.mean())

    fig_scatter.add_scatter(
        x=x_line, y=y_line,
        mode="lines",
        name=f"OLS Œ≤={beta:.2f}",
        line=dict(width=2, color="orange")
    )

    fig_scatter.update_layout(**default_layout)

    # =========================
    #  DISPLAY LAYOUT
    # =========================
    colA1, colA2, colA3 = st.columns(3)
    colB1, colB2, colB3 = st.columns(3)

    colA1.plotly_chart(fig_returns, width='stretch')
    colA2.plotly_chart(fig_spread, width='stretch')
    colA3.plotly_chart(fig_scatter, width='stretch')

    colB1.plotly_chart(fig_z, width='stretch')
    colB2.plotly_chart(fig_corr, width='stretch')

# ============================================================
# TAB 2 : PAIR SCREENER (FINAL DESK-GRADE ‚Äî MULTIPROC SAFE)
# ============================================================

# ---------- Session state init ----------
if "scanner_df" not in st.session_state:
    st.session_state["scanner_df"] = None

if "scanner_view_df" not in st.session_state:
    st.session_state["scanner_view_df"] = None

with tab_scanner:
    st.subheader("Pair Screener")


    # -----------------------------
    # Registry
    # -----------------------------
    @st.cache_data
    def load_registry():
        return pd.read_csv("data/asset_registry.csv")


    registry = load_registry()
    universes = sorted(registry["category_name"].unique())

    # -----------------------------
    # Controls
    # -----------------------------
    scan_mode = st.radio(
        "Scan mode",
        ["Single universe", "All universes"],
        horizontal=True,
        key="scanner_mode",
    )

    universe = None
    if scan_mode == "Single universe":
        universe = st.selectbox(
            "Universe",
            universes,
            key="scanner_universe",
        )

    run = st.button("Run scan", key="scanner_run_btn")

    # -----------------------------
    # Run scanner (multiprocessing)
    # -----------------------------
    if run:
        from utils.scanner import scan_all_universes, scan_universe
        import os

        with st.spinner("Scanning universes (multiprocessing)..."):

            # ---------- Prepare prices per universe (SEQUENTIAL, FAST) ----------
            universe_prices = {}

            target_universes = (
                [universe] if scan_mode == "Single universe" else universes
            )

            for univ in target_universes:
                tickers = (
                    registry
                    .loc[registry["category_name"] == univ, "asset"]
                    .str.upper()
                    .tolist()
                )
                tickers = [t for t in tickers if t in raw_data_list]
                if len(tickers) < 2:
                    continue

                series = {}
                for t in tickers:
                    df = cached_load_price(t, SCANNER_DATA_PATH)
                    df["log"] = np.log(df["close"])
                    df["norm"] = df["log"] - df["log"].iloc[0]
                    series[t] = df.set_index("datetime")["norm"]

                prices = pd.DataFrame(series).dropna(how="all")
                if prices.shape[1] >= 2:
                    universe_prices[univ] = prices

            if not universe_prices:
                st.warning("No valid universes to scan.")
            else:
                # ---------- TRUE MULTIPROCESSING ----------
                df_scan = scan_all_universes(
                    universe_prices,
                    max_workers=max(1, os.cpu_count() - 1),
                )

                if df_scan.empty:
                    st.warning("No pairs found.")
                else:
                    # ---------- Global ranking ----------
                    elig_rank = {"ELIGIBLE": 0, "WATCH": 1, "OUT": 2}
                    df_scan["_er"] = df_scan["eligibility"].map(elig_rank)

                    df_scan = (
                        df_scan
                        .sort_values(
                            ["_er", "eligibility_score"],
                            ascending=[True, False],
                        )
                        .drop(columns="_er")
                        .reset_index(drop=True)
                    )

                    # ---------- Compact view ----------
                    view_cols = [
                        "asset_1",
                        "asset_2",
                        "universe",
                        "eligibility",
                        "eligibility_score",
                        "n_valid_windows",
                        "12m_corr",
                        "6m_half_life",
                        "beta_std",
                    ]

                    df_view = df_scan[view_cols].copy()
                    df_view.rename(columns={
                        "asset_1": "Asset 1",
                        "asset_2": "Asset 2",
                        "eligibility": "Status",
                        "eligibility_score": "Score",
                        "n_valid_windows": "Valid windows",
                        "12m_corr": "Corr (12m)",
                        "6m_half_life": "HL (6m)",
                        "beta_std": "Œ≤ std",
                    }, inplace=True)

                    # ---------- Rounding (display only) ----------
                    ROUND = {
                        "Score": 3,
                        "Corr (12m)": 3,
                        "HL (6m)": 2,
                        "Œ≤ std": 3,
                    }
                    for c, n in ROUND.items():
                        if c in df_view.columns:
                            df_view[c] = df_view[c].astype(float).round(n)

                    # ---------- Persist ----------
                    st.session_state["scanner_df"] = df_scan
                    st.session_state["scanner_view_df"] = df_view

    # -----------------------------
    # Display persisted results
    # -----------------------------
    df_scan = st.session_state.get("scanner_df")
    df_view = st.session_state.get("scanner_view_df")

    if df_scan is not None and df_view is not None:

        st.markdown("### Ranked pairs")
        st.dataframe(df_view, width='stretch')

        # -----------------------------
        # Detailed diagnostics (eligible only)
        # -----------------------------
        show_details = st.toggle(
            "Show detailed diagnostics (eligible only)",
            key="scanner_show_details",
        )

        if show_details:
            elig_df = df_scan[df_scan["eligibility"] == "ELIGIBLE"]

            if elig_df.empty:
                st.info("No eligible pairs.")
            else:
                labels = [
                    f"{r.asset_1} / {r.asset_2} [{r.universe}]"
                    for r in elig_df.itertuples()
                ]

                sel = st.selectbox(
                    "Select pair",
                    labels,
                    key="scanner_detail_pair",
                )

                row = elig_df.iloc[labels.index(sel)]

                diag_cols = [
                    "3m_corr", "3m_adf_p", "3m_eg_p", "3m_half_life",
                    "6m_corr", "6m_adf_p", "6m_eg_p", "6m_half_life",
                    "12m_corr", "12m_adf_p", "12m_eg_p", "12m_half_life",
                    "beta_std",
                ]

                diag = row[diag_cols].to_frame("value")
                diag["value"] = diag["value"].astype(float).round(4)

                st.markdown("#### Multi-window statistics")
                st.dataframe(diag, width='stretch')

        # -----------------------------
        # Load pair into monitor
        # -----------------------------
        st.markdown("### Load pair")

        idx = st.number_input(
            "Row index",
            min_value=0,
            max_value=len(df_view) - 1,
            step=1,
            value=0,
            key="scanner_load_idx",
        )

        if st.button("Load selected pair", key="scanner_load_btn"):
            row = df_scan.iloc[int(idx)]
            st.session_state["asset1"] = row["asset_1"]
            st.session_state["asset2"] = row["asset_2"]
            st.session_state["go_to_monitor"] = True
            st.rerun()

# ============================================================
# TAB 3 : BACKTEST PAIR
# ============================================================


# ============================================================
# TAB ‚Äî MONTHLY UNIVERSE
# ============================================================
with tab_universe:
    st.title("Monthly Universe")

    df_mu = load_monthly_universe()
    if df_mu is None or df_mu.empty:
        st.warning("No monthly universe found. Run scripts/build_monthly_universe.py first.")
    else:
        months = sorted(df_mu["trade_month"].unique())
        sel_month = st.selectbox("Trading month", months, index=len(months) - 1, key="mu_month")

        df_m = df_mu[df_mu["trade_month"] == sel_month].copy()
        df_m = df_m.sort_values("rank")

        if "trade_start" in df_m.columns and "trade_end" in df_m.columns and len(df_m) > 0:
            st.caption(f"Trading period: {df_m['trade_start'].iloc[0].date()} ‚Üí {df_m['trade_end'].iloc[0].date()}")

        view_cols = [c for c in ["rank", "asset_1", "asset_2", "eligibility_score", "n_valid_windows", "beta_std"] if
                     c in df_m.columns]
        st.dataframe(df_m[view_cols], width="stretch")

        st.markdown("### Load pair into Pair Monitor")
        if len(df_m) > 0:
            labels = [f"{r.asset_1} / {r.asset_2} (rank={int(r.rank)})" for r in df_m.itertuples(index=False)]
            pick = st.selectbox("Pick a pair", labels, key="mu_pick")
            if st.button("Load into Pair Monitor", key="mu_load"):
                row = df_m.iloc[labels.index(pick)]
                st.session_state["asset1"] = str(row["asset_1"]).upper()
                st.session_state["asset2"] = str(row["asset_2"]).upper()
                st.session_state["go_to_monitor"] = True
                st.rerun()

# ============================================================
# TAB ‚Äî MONTHLY BACKTEST (BATCH)
# ============================================================
with tab_mbt:
    st.subheader("Monthly Backtest (batch)")

    df_mu = load_monthly_universe()
    if df_mu is None or df_mu.empty:
        st.warning("No monthly universe found. Run build_monthly_universe.py first.")
    else:
        months = sorted(df_mu["trade_month"].unique())
        sel_month = st.selectbox(
            "Trading month",
            months,
            index=len(months) - 1,
            key="mbt_month",
        )

        df_m = df_mu[df_mu["trade_month"] == sel_month].copy()
        if not df_m.empty:
            st.caption(
                f"Trading period: {pd.to_datetime(df_m['trade_start'].iloc[0]).date()} ‚Üí "
                f"{pd.to_datetime(df_m['trade_end'].iloc[0]).date()}"
            )

        st.markdown("### Strategy parameters (global)")

        c1, c2, c3, c4, c5 = st.columns(5)
        mbt_z_entry = c1.slider("z_entry", 1.0, 4.0, 2.0, 0.1, key="mbt_z_entry")
        mbt_z_exit = c2.slider("z_exit", 0.0, 2.0, 0.4, 0.05, key="mbt_z_exit")
        mbt_z_stop = c3.slider("z_stop", 2.0, 8.0, 4.0, 0.1, key="mbt_z_stop")
        mbt_z_window = c4.slider("z_window", 20, 200, 60, 10, key="mbt_z_window")
        mbt_fees = c5.number_input("fees (round-trip)", value=0.0002, format="%.6f", key="mbt_fees")

        st.markdown("### Estimation regime")

        beta_mode = st.selectbox(
            "beta_mode",
            ["monthly", "wf"],
            index=0,  # monthly par d√©faut
            help='monthly: beta estim√© √† scan_date et fig√© sur le mois. wf: beta recalcul√© en walk-forward.',
            key="mbt_beta_mode",
        )

        w1, w2 = st.columns(2)
        mbt_wf_train = w1.slider("wf_train (beta lookback)", 50, 500, 120, 10, key="mbt_wf_train")

        if beta_mode == "wf":
            mbt_wf_test = w2.slider("wf_test (re-hedge freq)", 10, 200, 30, 10, key="mbt_wf_test")
        else:
            mbt_wf_test = 30
            w2.info("wf_test non utilis√© en beta_mode=monthly")

        run_btn = st.button("Run monthly batch backtest", key="mbt_run")

        if run_btn:
            with st.spinner("Running monthly batch backtest..."):
                cfg = BatchConfig(
                    data_path=PROJECT_PATH / "data" / "raw" / "d1",
                    monthly_universe_path=PROJECT_PATH / "data" / "universe" / "monthly_universe.parquet",
                    out_dir=PROJECT_PATH / "data" / "backtests" / "monthly",
                    universe_name=None,   # ou "sweden" si tu veux forcer ici
                    timeframe="Daily",
                    warmup_extra=50,
                    equal_weight=True,
                )

                params = StrategyParams(
                    z_entry=float(mbt_z_entry),
                    z_exit=float(mbt_z_exit),
                    z_stop=float(mbt_z_stop),
                    z_window=int(mbt_z_window),
                    wf_train=int(mbt_wf_train),
                    wf_test=int(mbt_wf_test),
                    fees=float(mbt_fees),
                    beta_mode=str(beta_mode),
                )

                res = run_monthly_batch(cfg, params, trade_month=str(sel_month))
                st.session_state["mbt_res"] = res
                st.session_state["mbt_last_month"] = sel_month
                st.success("Done.")

        res = st.session_state.get("mbt_res", None)
        if res is None or res.get("pairs_metrics", pd.DataFrame()).empty:
            st.info("Run the batch to display results.")
        else:
            pairs_metrics = res["pairs_metrics"]
            portfolio_equity = res["portfolio_equity"]

            st.markdown("### Portfolio equity (month)")

            if portfolio_equity is not None and not portfolio_equity.empty:
                pe = portfolio_equity[portfolio_equity["trade_month"] == sel_month].copy()
                pe["datetime"] = pd.to_datetime(pe["datetime"])
                pe = pe.sort_values("datetime")

                fig_pf = go.Figure()
                fig_pf.add_scatter(x=pe["datetime"], y=pe["pf_equity"], mode="lines", name="PF equity")
                fig_pf.update_layout(template="plotly_dark", height=380, margin=dict(l=20, r=20, t=40, b=20))
                st.plotly_chart(fig_pf, width="stretch")
            else:
                st.warning("No portfolio equity produced (no valid pairs for that month).")

            st.markdown("### Pair results (month)")

            pm = pairs_metrics[pairs_metrics["trade_month"] == sel_month].copy()
            pm = pm.sort_values(["Sharpe", "Total Return"], ascending=[False, False])

            show_cols = [
                "asset_1", "asset_2", "rank",
                "Sharpe", "Total Return", "Max Drawdown",
                "Final Equity", "Trades",
                "eligibility_score", "n_valid_windows", "beta_std",
                "beta_mode", "beta_ref",
                "wf_train", "wf_test", "z_window", "z_entry", "z_exit", "z_stop", "fees"
            ]
            show_cols = [c for c in show_cols if c in pm.columns]
            st.dataframe(pm[show_cols], width="stretch")

            st.markdown("### Load a pair into Pair Monitor")
            if len(pm) > 0:
                labels = [
                    f"{r.asset_1} / {r.asset_2} (Sharpe={r.Sharpe if pd.notna(r.Sharpe) else 'NA'})"
                    for r in pm.itertuples()
                ]
                sel = st.selectbox("Pick a pair", labels, key="mbt_pick_pair")

                if st.button("Load into Pair Monitor", key="mbt_load_pair"):
                    row = pm.iloc[labels.index(sel)]
                    st.session_state["asset1"] = row["asset_1"]
                    st.session_state["asset2"] = row["asset_2"]
                    st.session_state["go_to_monitor"] = True
                    st.rerun()

# ============================================================
# TAB ‚Äî GLOBAL WALK-FORWARD BACKTEST
# ============================================================
with tab_global:
    st.subheader("Backtest Global (WF)")

    st.markdown("### Strategy parameters (GLOBAL, fixed)")

    c1, c2, c3, c4, c5 = st.columns(5)
    g_z_entry = c1.slider("z_entry", 1.0, 4.0, 2.0, 0.1, key="g_z_entry")
    g_z_exit = c2.slider("z_exit", 0.0, 2.0, 0.4, 0.05, key="g_z_exit")
    g_z_stop = c3.slider("z_stop", 2.0, 8.0, 4.0, 0.1, key="g_z_stop")
    g_z_window = c4.slider("z_window", 20, 200, 60, 10, key="g_z_window")
    g_fees = c5.number_input("fees (round-trip)", value=0.0002, format="%.6f", key="g_fees")

    st.markdown("### Estimation regime")

    beta_mode = st.selectbox(
        "beta_mode",
        ["monthly", "wf"],
        index=0,  # monthly par d√©faut
        help='monthly: beta estim√© √† scan_date et fig√© sur le mois. wf: beta recalcul√© en walk-forward.',
        key="g_beta_mode",
    )

    w1, w2 = st.columns(2)
    g_wf_train = w1.slider("wf_train (beta lookback)", 50, 500, 120, 10, key="g_wf_train")

    if beta_mode == "wf":
        g_wf_test = w2.slider("wf_test (re-hedge freq)", 10, 200, 30, 10, key="g_wf_test")
    else:
        g_wf_test = 30
        w2.info("wf_test non utilis√© en beta_mode=monthly")

    run_global = st.button("Run GLOBAL walk-forward backtest", key="g_run")

    if run_global:
        with st.spinner("Running global walk-forward backtest..."):
            cfg = BatchConfig(
                data_path=PROJECT_PATH / "data" / "raw" / "d1",
                monthly_universe_path=PROJECT_PATH / "data" / "universe" / "monthly_universe.parquet",
                out_dir=PROJECT_PATH / "data" / "backtests" / "global",
                universe_name=None,  # ou "sweden" si tu veux restreindre
                timeframe="Daily",
                warmup_extra=50,
                equal_weight=True,
            )

            params = StrategyParams(
                z_entry=float(g_z_entry),
                z_exit=float(g_z_exit),
                z_stop=float(g_z_stop),
                z_window=int(g_z_window),
                wf_train=int(g_wf_train),
                wf_test=int(g_wf_test),
                fees=float(g_fees),
                beta_mode=str(beta_mode),
            )

            res = run_global_walkforward(cfg, params)
            st.session_state["global_res"] = res
            st.success("Global backtest completed.")

    res = st.session_state.get("global_res", None)
    if res is None or not res:
        st.info("Run the global backtest to display results.")
    else:
        eq = res.get("equity", pd.DataFrame())
        stats = res.get("stats", {})
        monthly = res.get("monthly", pd.DataFrame())

        if eq is None or eq.empty:
            st.warning("No equity produced (check monthly_universe / data availability).")
        else:
            eq = eq.copy()
            eq["datetime"] = pd.to_datetime(eq["datetime"])
            eq = eq.sort_values("datetime")

            st.markdown("### Global Equity Curve")
            fig = go.Figure()
            fig.add_scatter(x=eq["datetime"], y=eq["equity"], mode="lines", name="Equity")
            fig.update_layout(template="plotly_dark", height=420, margin=dict(l=20, r=20, t=40, b=20))
            st.plotly_chart(fig, width="stretch")

            c1, c2, c3, c4, c5 = st.columns(5)
            c1.metric("Final Equity", f"{stats.get('Final Equity', float('nan')):.2f}")
            c2.metric("CAGR", f"{stats.get('CAGR', 0.0)*100:.1f}%")
            c3.metric("Sharpe", f"{stats.get('Sharpe', float('nan')):.2f}")
            c4.metric("Max Drawdown", f"{stats.get('Max Drawdown', float('nan'))*100:.1f}%")
            c5.metric("Nb Trade", f"{stats.get('Nb Trade', float('nan')):.0f}")

            st.markdown("### Monthly returns")
            if monthly is None or monthly.empty:
                st.info("No monthly breakdown available.")
            else:
                st.dataframe(monthly, width="stretch")

            st.markdown("### All trades (global)")

            trades = res.get("trades", pd.DataFrame())
            if trades is None or trades.empty:
                st.info("No trades to display (run global backtest or check strategy thresholds).")
            else:
                # Filters
                c1, c2, c3 = st.columns(3)

                months = ["All"] + sorted(trades["trade_month"].astype(str).unique().tolist())
                sel_m = c1.selectbox("Filter month", months, index=0, key="g_trades_month")

                pairs = ["All"] + sorted(trades["pair_id"].astype(str).unique().tolist())
                sel_p = c2.selectbox("Filter pair", pairs, index=0, key="g_trades_pair")

                side_col = "Side" if "Side" in trades.columns else ("side" if "side" in trades.columns else None)
                if side_col:
                    sides = ["All"] + sorted(trades[side_col].astype(str).unique().tolist())
                    sel_s = c3.selectbox("Filter side", sides, index=0, key="g_trades_side")
                else:
                    sel_s = "All"

                df_t = trades.copy()
                if sel_m != "All":
                    df_t = df_t[df_t["trade_month"].astype(str) == sel_m]
                if sel_p != "All":
                    df_t = df_t[df_t["pair_id"].astype(str) == sel_p]
                if side_col and sel_s != "All":
                    df_t = df_t[df_t[side_col].astype(str) == sel_s]

                # Useful column ordering (keep the rest too)
                preferred = [
                    "trade_month", "pair_id", "asset_1", "asset_2",
                    "entry_datetime", "exit_datetime",
                    "beta_mode", "beta_ref",
                    "z_entry", "z_exit", "z_stop", "z_window", "fees",
                ]
                cols = [c for c in preferred if c in df_t.columns] + [c for c in df_t.columns if c not in preferred]

                st.dataframe(df_t[cols], width="stretch", height=520)

                # Export
                csv = df_t.to_csv(index=False).encode("utf-8")
                st.download_button(
                    "Download trades CSV",
                    data=csv,
                    file_name="global_trades.csv",
                    mime="text/csv",
                    key="g_trades_csv",
                )

with tab_backtest:
    st.subheader("Backtest Pair Trading")

    st.markdown("R√©glages des param√®tres de stat√©gie")
    bc1, bc2, bc3, bc4, bc5 = st.columns(5)

    z_entry = bc1.slider("Z-entry", 1.0, 4.0, 2.0, 0.1)
    z_exit = bc2.slider("Z-exit", 0.0, 2.0, 0.4, 0.05)
    z_stop = bc3.slider("Z-stop (|z|)", 2.0, 8.0, 4.0, 0.1)
    z_window = bc4.slider("Z-window", 20, 200, 60, 10)
    fees = bc5.number_input("Fees (round trip)", value=0.0002, format="%.6f")

    st.markdown("R√©glages du walk-forward")
    wf1, wf2 = st.columns(2)
    wf_train = wf1.slider("WF Train Window", 50, 500, 120, 10)
    wf_test = wf2.slider("WF Test Window", 10, 200, 30, 10)

    # ------------------------------------------------------------
    #  AUTO-RUN DU BACKTEST (pas de bouton)
    # ------------------------------------------------------------

    st.subheader(f"Backtest results for {asset1} / {asset2}")

    with st.spinner("Running backtest..."):

        # --- WALK-FORWARD SPREAD & ZSCORE ---
        spread_bt, zscore_bt, beta_wf = walk_forward_beta_spread_zscore(
            merged[f"norm_{asset1}"],
            merged[f"norm_{asset2}"],
            train=wf_train,
            test=wf_test,
            z_window=z_window,
        )

        equity, trades, pnl_list = backtest_pair(
            spread_bt,
            zscore_bt,
            merged[f"norm_{asset1}"],
            merged[f"norm_{asset2}"],
            beta=beta,
            beta_series=beta_wf,
            z_entry=z_entry,
            z_exit=z_exit,
            z_stop=z_stop,
            fees=fees,
        )

        # Inject equity into merged for WF segment analytics
        merged["PnL_equity"] = equity.values

        segments = walk_forward_segments(len(merged), wf_train, wf_test)

        metrics = compute_metrics(equity, trades)

    # ============================================================
    # Equity Curve
    # ============================================================
    fig_eq = go.Figure()
    fig_eq.add_scatter(
        x=merged["datetime"],
        y=equity,
        mode="lines",
        line=dict(width=2, color="#00c3ff"),
        name="Equity"
    )
    fig_eq.update_layout(
        height=350,
        template="plotly_dark",
        margin=dict(l=20, r=20, t=40, b=20),
        plot_bgcolor="rgba(0,0,0,0)",
        paper_bgcolor="rgba(0,0,0,0)",
    )

    st.plotly_chart(fig_eq, width='stretch')

    # ============================================================
    # METRICS
    # ============================================================

    m1, m2, m3, m4, m5 = st.columns(5)
    m6, m7, m8, m9, m10, m11 = st.columns(6)

    m1.metric("Final Equity", f"{metrics['Final Equity']:.3f}")
    m2.metric("Total Return", f"{metrics['Total Return'] * 100:.1f}%")
    m3.metric("Sharpe", f"{metrics['Sharpe']:.2f}")
    m4.metric("Max DD", f"{metrics['Max Drawdown'] * 100:.1f}%")

    m5.metric("Nb Trades", f"{metrics['Trades']}")
    winrate_display = f"{metrics['Winrate'] * 100:.1f}%" if metrics['Trades'] > 0 else "N/A"
    m6.metric("Winrate", winrate_display)

    avg_win_disp = f"{metrics['AvgWinningTrade'] * 100:.2f}%" if not np.isnan(metrics['AvgWinningTrade']) else "N/A"
    avg_loss_disp = f"{metrics['AvgLosingTrade'] * 100:.2f}%" if not np.isnan(metrics['AvgLosingTrade']) else "N/A"

    m7.metric("Avg Winning Trade", avg_win_disp)
    m8.metric("Avg Losing Trade", avg_loss_disp)

    m9.metric("Max Consecutive Wins", f"{metrics['MaxConsecWins']}")
    m10.metric("Max Consecutive Losses", f"{metrics['MaxConsecLosses']}")

    m11.metric("Avg Trade Duration", f"{metrics['AvgTradeDuration']:.1f} bars")

    # ============================================================
    # Trade List
    # ============================================================
    st.markdown("### Trade List")

    if len(trades) == 0:
        st.info("No trades taken with these parameters.")
    else:
        df_trades = pd.DataFrame(trades)
        df_trades.index.name = "Trade #"

        df_trades["PnL_total"] = df_trades["PnL_total"].round(5)
        df_trades["PnL_Y"] = df_trades["PnL_Y"].round(5)
        df_trades["PnL_X"] = df_trades["PnL_X"].round(5)
        df_trades["Duration"] = df_trades["Duration"].astype(int)

        st.dataframe(df_trades, width='stretch')

        # ============================================================
        # TRADE VISUALIZATION (Spread WF + classic spread background)
        # ============================================================
        st.markdown("### Trade Visualization")

        fig_trades = go.Figure()

        # ---- Ajout du spread classique (gris, discret) ----
        fig_trades.add_scatter(
            x=merged["datetime"],
            y=merged["spread"],
            mode="lines",
            name="Spread (classic)",
            line=dict(color="rgba(150,150,150,0.25)", width=1),
            showlegend=True
        )

        # ---- Spread WF (principal) ----
        fig_trades.add_scatter(
            x=merged["datetime"],
            y=spread_bt,
            mode="lines",
            name="Spread (WF)",
            line=dict(color="#00c3ff", width=2),
            showlegend=True
        )

        # ---- Markers entr√©es/sorties ----
        for t in trades:
            entry_i = t["Entry_index"]
            exit_i = t["Exit_index"]
            side = t["Side"]

            entry_color = "#00ff00" if "Long" in side else "#ff3300"
            exit_color = "white" if not t["Stopped"] else "#ff6600"

            fig_trades.add_scatter(
                x=[merged["datetime"].iloc[entry_i]],
                y=[spread_bt.iloc[entry_i]],
                mode="markers",
                marker=dict(size=10, color=entry_color),
                showlegend=False
            )

            fig_trades.add_scatter(
                x=[merged["datetime"].iloc[exit_i]],
                y=[spread_bt.iloc[exit_i]],
                mode="markers",
                marker=dict(size=10, color=exit_color, symbol="circle-open"),
                showlegend=False
            )

        fig_trades.update_layout(
            height=350,
            template="plotly_dark",
            margin=dict(l=20, r=20, t=40, b=20),
            plot_bgcolor="rgba(0,0,0,0)",
            paper_bgcolor="rgba(0,0,0,0)",
            yaxis_title="Spread"
        )

        st.plotly_chart(fig_trades, width='stretch')

        # ============================================================
        # Z-SCORE VISUALIZATION
        # ============================================================
        st.markdown("### Z-Score Confirmation")

        fig_ztrades = go.Figure()

        fig_ztrades.add_scatter(
            x=merged["datetime"],
            y=zscore_bt,
            mode="lines",
            name="Z-score",
            line=dict(color="#ffaa00", width=2),
        )

        fig_ztrades.add_hline(y=z_entry, line_dash="dot", line_color="#ff6600")
        fig_ztrades.add_hline(y=-z_entry, line_dash="dot", line_color="#ff6600")
        fig_ztrades.add_hline(y=z_exit, line_dash="dot", line_color="white", opacity=0.3)
        fig_ztrades.add_hline(y=-z_exit, line_dash="dot", line_color="white", opacity=0.3)
        fig_ztrades.add_hline(y=z_stop, line_dash="dot", line_color="red")
        fig_ztrades.add_hline(y=-z_stop, line_dash="dot", line_color="red")

        for t in trades:
            entry_i = t["Entry_index"]
            exit_i = t["Exit_index"]
            side = t["Side"]

            entry_color = "#00ff00" if "Long" in side else "#ff3300"
            exit_color = "white" if not t["Stopped"] else "#ff6600"

            fig_ztrades.add_scatter(
                x=[merged["datetime"].iloc[entry_i]],
                y=[zscore_bt.iloc[entry_i]],
                mode="markers",
                marker=dict(size=10, color=entry_color),
                showlegend=False
            )

            fig_ztrades.add_scatter(
                x=[merged["datetime"].iloc[exit_i]],
                y=[zscore_bt.iloc[exit_i]],
                mode="markers",
                marker=dict(size=10, color=exit_color, symbol="circle-open"),
                showlegend=False
            )

        fig_ztrades.update_layout(
            height=350,
            template="plotly_dark",
            margin=dict(l=20, r=20, t=40, b=20),
            plot_bgcolor="rgba(0,0,0,0)",
            paper_bgcolor="rgba(0,0,0,0)",
            yaxis_title="Z-score",
        )

        st.plotly_chart(fig_ztrades, width='stretch')

        # ============================================================
        # Walk-Forward Hedge Ratio (Œ≤ WF) - clean view
        # ============================================================

        st.markdown("### Walk-Forward Hedge Ratio (Œ≤ WF)")

        fig_wf = go.Figure()

        # 1) Courbe Œ≤_WF
        fig_wf.add_scatter(
            x=merged["datetime"],
            y=beta_wf,
            mode="lines",
            name="Œ≤_WF",
            line=dict(color="#ffb347", width=2),
        )

        # 2) Traits verticaux aux changements de Œ≤
        beta_series = pd.Series(beta_wf)

        change_idx = beta_series[
            beta_series.notna() & (beta_series != beta_series.shift())
            ].index

        for i in change_idx:
            fig_wf.add_vline(
                x=merged["datetime"].iloc[i],
                line_width=1,
                line_color="rgba(0, 200, 255, 0.5)",
            )

        fig_wf.update_layout(
            height=220,
            template="plotly_dark",
            margin=dict(l=20, r=20, t=40, b=20),
            plot_bgcolor="rgba(0,0,0,0)",
            paper_bgcolor="rgba(0,0,0,0)",
            yaxis_title="Œ≤ (WF)",
            showlegend=True,
        )

        st.plotly_chart(fig_wf, width='stretch')

        # ============================================================
        # WALK-FORWARD SEGMENT REPORT
        # ============================================================

        st.markdown("## Walk-Forward Segment Report")

        df_wf_report = compute_segment_metrics(merged, trades, beta_wf, segments)

        # Supprimer les segments sans trade
        df_wf_report = df_wf_report[df_wf_report["Trades"] > 0].reset_index(drop=True)

        if df_wf_report.empty:
            st.info("No walk-forward segments with trades for this configuration.")
        else:
            st.dataframe(df_wf_report.style.format({
                "Beta": "{:.3f}",
                "Winrate": "{:.1%}",
                "AvgPnL": "{:.4f}",
                "Sharpe": "{:.2f}",
                "MaxDD": "{:.1%}"
            }))

        # ============================================================
        # WALK-FORWARD HEATMAP
        # ============================================================

        st.markdown("### WF Segment Performance Heatmap")

        if df_wf_report.empty:
            st.info("Heatmap unavailable: no segments with trades.")
        else:
            heatmap_df = df_wf_report.copy()
            heatmap_df["Segment"] = heatmap_df["Segment"].astype(str)

            fig_heat = px.imshow(
                heatmap_df[["AvgPnL", "Winrate", "Sharpe"]].T,
                labels=dict(x="Segment", y="Metric", color="Value"),
                x=heatmap_df["Segment"],
                y=["AvgPnL", "Winrate", "Sharpe"],
                color_continuous_scale="RdYlGn"
            )

            fig_heat.update_layout(
                height=400,
                template="plotly_dark",
                margin=dict(l=20, r=20, t=40, b=20)
            )

            st.plotly_chart(fig_heat, width='stretch')

with tab_opt:
    st.subheader("Optimisation robuste (r√©el + synth√©tique)")


    # -----------------------------
    # Helper rerun compatible
    # -----------------------------
    def _rerun():
        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
        else:
            return


    # -----------------------------
    # Portfolio registry helpers
    # -----------------------------
    import json
    from datetime import datetime

    REGISTRY_PATH = PROJECT_PATH / "data" / "portfolio_registry.json"


    def _load_registry(path: Path) -> list[dict]:
        if not path.exists():
            return []
        try:
            return json.loads(path.read_text(encoding="utf-8"))
        except Exception:
            return []


    def _save_registry(path: Path, records: list[dict]) -> None:
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(json.dumps(records, indent=2, ensure_ascii=False), encoding="utf-8")


    def _upsert_pair(records: list[dict], item: dict) -> list[dict]:
        # cl√© stable : pair_id + timeframe + source
        key = (item.get("pair_id"), item.get("timeframe"), item.get("source"))
        out = []
        replaced = False
        for r in records:
            rk = (r.get("pair_id"), r.get("timeframe"), r.get("source"))
            if rk == key:
                out.append(item)
                replaced = True
            else:
                out.append(r)
        if not replaced:
            out.append(item)
        return out


    # -----------------------------
    # Inputs
    # -----------------------------
    c1, c2, c3 = st.columns(3)
    n_synth = c1.number_input("Nb trajectoires synth√©tiques", 10, 500, 50)
    n_param = c2.number_input("Nb de combinaisons de param√®tres", 5, 200, 20)
    seed = c3.number_input("Seed RNG", 0, 999999, 42)

    st.markdown("### Plages de param√®tres")

    p1, p2, p3, p4 = st.columns(4)
    z_entry_range = p1.slider("Z-entry", 1.0, 4.0, (1.2, 2.5), 0.1)
    z_exit_range = p2.slider("Z-exit", 0.0, 2.0, (0.2, 0.8), 0.05)
    z_window_range = p3.slider("Z-window", 20, 200, (40, 80), 5)
    wf_train_range = p4.slider("WF-train", 50, 500, (100, 200), 10)

    # -----------------------------
    # Run optimization
    # -----------------------------
    run_opt = st.button("Lancer optimisation")

    if run_opt:
        with st.spinner("Optimisation en cours."):
            df_opt = run_full_optimization(
                merged,
                asset1,
                asset2,
                df1,
                df2,
                spread,
                beta,
                int(n_synth),
                int(n_param),
                z_entry_range,
                z_exit_range,
                z_window_range,
                wf_train_range,
                int(seed),
            )

            st.session_state["df_opt"] = df_opt.copy()
            st.session_state["opt_done"] = True

            if "selected_index" not in st.session_state:
                st.session_state["selected_index"] = 0
            if "selected_opt_params" not in st.session_state:
                st.session_state["selected_opt_params"] = None

            st.session_state.pop("diag_results", None)
            st.session_state.pop("diag_param_key", None)

            st.success("Optimisation termin√©e !")

    # -----------------------------
    # Show results if available
    # -----------------------------
    if st.session_state.get("opt_done", False) and "df_opt" in st.session_state:
        df_opt = st.session_state["df_opt"]

        st.markdown("### R√©sultats")
        st.dataframe(df_opt, width='stretch')

        st.markdown("### Explorer une configuration")

        default_idx = int(st.session_state.get("selected_index", 0))
        default_idx = max(0, min(default_idx, len(df_opt) - 1))

        selected_index = st.number_input(
            "Index de la ligne √† explorer",
            min_value=0,
            max_value=len(df_opt) - 1,
            step=1,
            value=default_idx,
        )

        col_btn1, col_btn2 = st.columns([1, 1])
        with col_btn1:
            explore = st.button("Explorer cette configuration", key="explore_opt_config")
        with col_btn2:
            clear = st.button("Effacer la s√©lection", key="clear_opt_config")

        if clear:
            st.session_state["selected_index"] = 0
            st.session_state["selected_opt_params"] = None
            st.session_state.pop("diag_results", None)
            st.session_state.pop("diag_param_key", None)
            _rerun()

        if explore:
            st.session_state["selected_index"] = int(selected_index)
            st.session_state["selected_opt_params"] = df_opt.iloc[int(selected_index)].to_dict()
            st.session_state.pop("diag_results", None)
            st.session_state.pop("diag_param_key", None)
            _rerun()

        # -----------------------------
        # Exploration
        # -----------------------------
        params = st.session_state.get("selected_opt_params", None)

        if params is not None:
            st.markdown("---")
            st.markdown("## üîé Exploration de la configuration s√©lectionn√©e")

            # Preview "lisible" (plus impactant que st.json brut)
            k1, k2, k3, k4 = st.columns(4)
            k1.metric("Sharpe (r√©el)", f"{params.get('Sharpe_real', np.nan):.3f}")
            k2.metric("Sharpe m√©dian (synth)", f"{params.get('Sharpe_median', np.nan):.3f}")
            k3.metric("Robustness", f"{params.get('Robustness', np.nan):.3f}")
            k4.metric("Sharpe min (synth)", f"{params.get('Sharpe_min', np.nan):.3f}")

            with st.expander("Voir param√®tres (JSON)", expanded=False):
                st.json(params)

            # Recompute WF spread/zscore/beta (pipeline canonique)
            spread_bt, zscore_bt, beta_wf = walk_forward_beta_spread_zscore(
                merged[f"norm_{asset1}"],
                merged[f"norm_{asset2}"],
                train=int(params["wf_train"]),
                test=int(params["wf_test"]),
                z_window=int(params["z_window"]),
            )

            # Backtest (WF beta locked at entry)
            FEES = 0.0002
            Z_STOP_MULT = 2.0

            equity, trades, pnl_list = backtest_pair(
                spread_bt,
                zscore_bt,
                merged[f"norm_{asset1}"],
                merged[f"norm_{asset2}"],
                beta=float(beta),  # <- beta fallback EXACT (important)
                beta_series=beta_wf,  # <- WF beta
                z_entry=float(params["z_entry"]),
                z_exit=float(params["z_exit"]),
                z_stop=float(params["z_entry"]) * Z_STOP_MULT,
                fees=FEES,
            )

            # ---- Add to portfolio (freeze params + beta_ref + lookback)
            add_c1, add_c2, add_c3 = st.columns([1.2, 2.8, 2.0])
            with add_c1:
                add_pf = st.button("Ajouter au portefeuille", key="add_to_pf_btn")
            with add_c2:
                st.caption(f"Enregistre la paire + param√®tres dans {REGISTRY_PATH.name} (upsert).")
            with add_c3:
                note = st.text_input("Note (optionnel)", key="pf_note", placeholder="ex: robuste / √† surveiller")

            if add_pf:
                records = _load_registry(REGISTRY_PATH)

                item = {
                    "pair_id": f"{asset1}-{asset2}",
                    "asset1": asset1,
                    "asset2": asset2,
                    "timeframe": timeframe,
                    "source": source,
                    "lb_used": int(lb),  # <- lookback utilis√© au moment de l'exploration (critique)
                    "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "notes": note or "",
                    "params": {
                        "z_entry": float(params["z_entry"]),
                        "z_exit": float(params["z_exit"]),
                        "z_window": int(params["z_window"]),
                        "wf_train": int(params["wf_train"]),
                        "wf_test": int(params["wf_test"]),
                        "fees": float(FEES),
                        "z_stop_mult": float(Z_STOP_MULT),
                        "beta_ref": float(beta),  # <- pour reproduire EXACTEMENT l‚Äôexploration
                    },
                    "metrics": {
                        "Sharpe_real": float(params.get("Sharpe_real", np.nan)),
                        "Sharpe_median": float(params.get("Sharpe_median", np.nan)),
                        "Sharpe_min": float(params.get("Sharpe_min", np.nan)),
                        "Sharpe_std": float(params.get("Sharpe_std", np.nan)),
                        "Robustness": float(params.get("Robustness", np.nan)),
                    },
                }

                records = _upsert_pair(records, item)
                _save_registry(REGISTRY_PATH, records)
                st.success("Ajout√© au portefeuille (upsert).")

            # ---- Charts / tables
            st.markdown("### Equity Curve")
            fig_eq = go.Figure()
            fig_eq.add_scatter(x=merged["datetime"], y=equity, mode="lines", name="Equity")
            fig_eq.update_layout(template="plotly_dark", height=350, margin=dict(l=20, r=20, t=40, b=20))
            st.plotly_chart(fig_eq, width='stretch')

            st.markdown("### Trades")
            if len(trades) > 0:
                st.dataframe(pd.DataFrame(trades), width='stretch')
            else:
                st.info("Aucun trade pour cette configuration.")

            # ============================================================
            # Diagnostics: Real vs Synthetic (Z-score distribution + Half-life)
            # ============================================================
            st.markdown("---")
            st.markdown("## üß™ Diagnostics : R√©el vs Synth√©tique")

            d1, d2, d3 = st.columns(3)
            diag_n = d1.slider("Nb paths synth (diagnostic)", 5, 200, 30, 5, key="diag_n")
            diag_seed = d2.number_input("Seed (diagnostic)", 0, 999999, 123, key="diag_seed")
            sample_per_path = d3.slider("Samples zscore / path", 200, 5000, 1500, 100, key="diag_sample_per_path")

            run_diag = st.button("Run diagnostics", key="run_diag_btn")

            diag_param_key = (
                asset1, asset2,
                int(params["wf_train"]), int(params["wf_test"]), int(params["z_window"]),
                float(params["z_entry"]), float(params["z_exit"]),
                int(diag_n), int(diag_seed), int(sample_per_path)
            )

            if run_diag:
                with st.spinner("Diagnostics en cours (r√©el vs synth)."):
                    rng = np.random.default_rng(int(diag_seed))

                    real_spread = pd.Series(spread_bt).dropna()
                    real_z = pd.Series(zscore_bt).dropna()

                    real_hl = compute_half_life(real_spread)
                    real_hl_val = float(real_hl) if (real_hl is not None and np.isfinite(real_hl)) else np.nan

                    real_z_vals = real_z.to_numpy()
                    real_z_vals = real_z_vals[np.isfinite(real_z_vals)]
                    if len(real_z_vals) > sample_per_path:
                        real_z_vals = rng.choice(real_z_vals, size=int(sample_per_path), replace=False)

                    spread_ref = pd.Series(spread_bt).dropna()
                    calib = calibrate_params_from_pair(df1, df2, spread_ref, float(beta))

                    synth_hl = []
                    synth_z_samples = []
                    n_steps_diag = len(merged)

                    for _ in range(int(diag_n)):
                        A_s, B_s, *_ = simulate_cointegrated_assets(
                            n_steps_diag,
                            beta=float(beta),
                            X0=calib["X0"], v0=calib["v0"], mu=calib["mu"],
                            theta=calib["theta"], kappa=calib["kappa"],
                            xi=calib["xi"], rho=calib["rho"],
                            mu_s=calib["mu_s"], theta_s=calib["theta_s"],
                            sigma_s=calib["sigma_s"], S0=calib["S0"],
                        )

                        spread_bt_s, zscore_bt_s, _beta_wf_s = walk_forward_beta_spread_zscore(
                            pd.Series(A_s),
                            pd.Series(B_s),
                            train=int(params["wf_train"]),
                            test=int(params["wf_test"]),
                            z_window=int(params["z_window"]),
                        )

                        z_sim_vals = pd.Series(zscore_bt_s).to_numpy()
                        z_sim_vals = z_sim_vals[np.isfinite(z_sim_vals)]
                        if len(z_sim_vals) > 0:
                            take = min(int(sample_per_path), len(z_sim_vals))
                            synth_z_samples.append(rng.choice(z_sim_vals, size=take, replace=False))

                        hl_sim = compute_half_life(pd.Series(spread_bt_s).dropna())
                        hl_sim_val = float(hl_sim) if (hl_sim is not None and np.isfinite(hl_sim)) else np.nan
                        synth_hl.append(hl_sim_val)

                    synth_hl = np.array(synth_hl, dtype=float)
                    synth_z_vals = np.concatenate(synth_z_samples) if len(synth_z_samples) else np.array([],
                                                                                                         dtype=float)


                    def _zstats(arr: np.ndarray):
                        arr = arr[np.isfinite(arr)]
                        if arr.size == 0:
                            return {"mean": np.nan, "std": np.nan, "q05": np.nan, "q50": np.nan, "q95": np.nan}
                        return {
                            "mean": float(np.mean(arr)),
                            "std": float(np.std(arr)),
                            "q05": float(np.quantile(arr, 0.05)),
                            "q50": float(np.quantile(arr, 0.50)),
                            "q95": float(np.quantile(arr, 0.95)),
                        }


                    real_z_stat = _zstats(real_z_vals)
                    synth_z_stat = _zstats(synth_z_vals)

                    diag_df = pd.DataFrame([
                        {
                            "Set": "Real (WF traded)",
                            "Half-life": real_hl_val,
                            **{f"Z_{k}": v for k, v in real_z_stat.items()},
                            "Z_samples": int(len(real_z_vals)),
                        },
                        {
                            "Set": f"Synth (n={int(diag_n)})",
                            "Half-life_median": float(np.nanmedian(synth_hl)) if np.isfinite(
                                np.nanmedian(synth_hl)) else np.nan,
                            "Half-life_std": float(np.nanstd(synth_hl)) if np.isfinite(np.nanstd(synth_hl)) else np.nan,
                            **{f"Z_{k}": v for k, v in synth_z_stat.items()},
                            "Z_samples": int(len(synth_z_vals)),
                        },
                    ])

                    st.session_state["diag_results"] = {
                        "diag_df": diag_df,
                        "real_z_vals": real_z_vals,
                        "synth_z_vals": synth_z_vals,
                        "synth_hl": synth_hl,
                    }
                    st.session_state["diag_param_key"] = diag_param_key

            if st.session_state.get("diag_param_key", None) == diag_param_key and "diag_results" in st.session_state:
                diag = st.session_state["diag_results"]
                diag_df = diag["diag_df"]
                real_z_vals = diag["real_z_vals"]
                synth_z_vals = diag["synth_z_vals"]
                synth_hl = diag["synth_hl"]

                st.markdown("### R√©sum√© (r√©el vs synth)")
                st.dataframe(diag_df, width='stretch')

                st.markdown("### Distribution des z-scores (√©chantillonn√©e)")
                plot_df = pd.DataFrame({
                    "zscore": np.concatenate([real_z_vals, synth_z_vals]) if (
                                len(real_z_vals) and len(synth_z_vals)) else
                    (real_z_vals if len(real_z_vals) else synth_z_vals),
                    "source": (["Real"] * len(real_z_vals)) + (["Synth"] * len(synth_z_vals)),
                })

                if len(plot_df) > 0:
                    fig_zdist = px.histogram(
                        plot_df,
                        x="zscore",
                        color="source",
                        barmode="overlay",
                        histnorm="probability density",
                        nbins=60,
                        opacity=0.55,
                    )
                    fig_zdist.update_layout(template="plotly_dark", height=350, margin=dict(l=20, r=20, t=40, b=20))
                    st.plotly_chart(fig_zdist, width='stretch')
                else:
                    st.info("Pas assez de donn√©es z-score pour tracer la distribution.")

                st.markdown("### Distribution des half-lives (synth√©tique)")
                hl_df = pd.DataFrame({"half_life": synth_hl})
                hl_df = hl_df[np.isfinite(hl_df["half_life"])]

                if len(hl_df) > 0:
                    fig_hl = px.histogram(hl_df, x="half_life", nbins=30)
                    fig_hl.update_layout(template="plotly_dark", height=300, margin=dict(l=20, r=20, t=40, b=20))
                    st.plotly_chart(fig_hl, width='stretch')
                else:
                    st.info("Half-life synth indisponible (NaN).")
            else:
                st.info("Clique sur 'Run diagnostics' pour comparer r√©el vs synth.")
    else:
        st.info("Lance une optimisation pour afficher les r√©sultats et explorer une configuration.")

with tab_pf:
    st.subheader("Portfolio (PF)")


    # -----------------------------
    # Helper rerun compatible
    # -----------------------------
    def _rerun():
        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()
        else:
            return


    # -----------------------------
    # Imports (PF registry + backtest)
    # -----------------------------
    from utils.portfolio_registry import load_registry, remove_pair_config, REGISTRY_PATH
    from utils.portfolio_backtest import (
        backtest_single_pair_from_config,
        backtest_portfolio_equal_weight,
    )

    # -----------------------------
    # Top controls (impact + clean)
    # -----------------------------
    c1, c2, c3 = st.columns([3, 3, 1])
    lb_pf = c1.number_input("Lookback bars (PF)", min_value=200, max_value=20000, value=3000, step=100)
    pf_periods_per_year = c2.number_input("Periods/year (Sharpe PF)", min_value=1, max_value=200000, value=252, step=1)
    c3.markdown("<div style='height: 28px;'></div>", unsafe_allow_html=True)
    run_pf = c3.button("Backtester le PF", key="run_pf_btn", width='stretch')

    st.caption(f"Registry: {REGISTRY_PATH}")

    # -----------------------------
    # Load registry
    # -----------------------------
    registry = load_registry(REGISTRY_PATH)
    if len(registry) == 0:
        st.info("Ton portefeuille est vide. Va dans Optimization > Explorer une config > Ajouter au portefeuille.")
    else:

        reg_df = pd.DataFrame(registry)

        # Flatten propre mais compact (on n‚Äôaffiche pas 50 colonnes)
        params_df = pd.json_normalize(reg_df["params"]).add_prefix(
            "p_") if "params" in reg_df.columns else pd.DataFrame()
        metrics_df = pd.json_normalize(reg_df["metrics"]).add_prefix(
            "m_") if "metrics" in reg_df.columns else pd.DataFrame()
        reg_flat = reg_df.drop(columns=[c for c in ["params", "metrics"] if c in reg_df.columns], errors="ignore")
        reg_flat = pd.concat(
            [reg_flat.reset_index(drop=True), params_df.reset_index(drop=True), metrics_df.reset_index(drop=True)],
            axis=1)

        show_cols = [c for c in [
            "pair_id", "asset1", "asset2", "timeframe", "created_at",
            "m_Robustness", "m_Sharpe_real", "m_Sharpe_median", "m_Sharpe_min",
            "p_z_entry", "p_z_exit", "p_z_window", "p_wf_train", "p_wf_test", "p_fees"
        ] if c in reg_flat.columns]


        # -----------------------------
        # Internal helpers
        # -----------------------------
        def _compute_sharpe_from_returns(rets: pd.Series, periods_per_year: int) -> float:
            r = rets.replace([np.inf, -np.inf], np.nan).dropna()
            if len(r) < 3:
                return 0.0
            std = float(r.std(ddof=1))
            if std == 0.0:
                return 0.0
            return float(r.mean() / std * np.sqrt(periods_per_year))


        def _max_drawdown(eq: pd.Series) -> float:
            eq = eq.replace([np.inf, -np.inf], np.nan).dropna()
            if len(eq) < 3:
                return 0.0
            peak = eq.cummax()
            dd = (eq / peak) - 1.0
            return float(dd.min())


        def _cagr_from_equity(eq: pd.Series) -> float:
            eq = eq.replace([np.inf, -np.inf], np.nan).dropna()
            if len(eq) < 3:
                return np.nan
            if not isinstance(eq.index, pd.DatetimeIndex):
                return np.nan
            years = (eq.index[-1] - eq.index[0]).total_seconds() / (365.25 * 24 * 3600)
            if years <= 0:
                return np.nan
            return float((eq.iloc[-1] / eq.iloc[0]) ** (1 / years) - 1)


        # -----------------------------
        # PF tabs (impactant)
        # -----------------------------
        t_overview, t_pairs, t_adv = st.tabs(["Overview", "Paires", "D√©tails (optionnel)"])

        # -----------------------------
        # Run PF backtest
        # -----------------------------
        pf_key = (
            tuple((it.get("pair_id"), it.get("timeframe")) for it in registry),
            int(lb_pf),
            int(pf_periods_per_year),
        )

        if run_pf:
            with st.spinner("Backtest PF en cours..."):
                per_pair_returns = {}
                per_pair_equity = {}
                per_pair_info = []

                for it in registry:
                    pair_id = it["pair_id"]
                    a1 = it["asset1"]
                    a2 = it["asset2"]
                    cfg_params = it["params"]

                    # --- Load data (m√™me pipeline que Pair Monitor)
                    df1_pf = cached_load_price(a1, DATA_PATH).iloc[-int(lb_pf):].copy()
                    df2_pf = cached_load_price(a2, DATA_PATH).iloc[-int(lb_pf):].copy()

                    # Log + norm
                    df1_pf["log"] = np.log(df1_pf["close"])
                    df2_pf["log"] = np.log(df2_pf["close"])

                    df1_pf["norm"] = df1_pf["log"] - df1_pf["log"].iloc[0]
                    df2_pf["norm"] = df2_pf["log"] - df2_pf["log"].iloc[0]

                    df1_pf["logret"] = df1_pf["log"].diff()
                    df2_pf["logret"] = df2_pf["log"].diff()

                    merged_pf = pd.merge(
                        df1_pf[["datetime", "norm", "logret"]],
                        df2_pf[["datetime", "norm", "logret"]],
                        on="datetime",
                        how="inner",
                        suffixes=(f"_{a1}", f"_{a2}"),
                    )

                    series_y = merged_pf[f"norm_{a1}"]
                    series_x = merged_pf[f"norm_{a2}"]
                    beta_pf = compute_hedge_ratio(series_y, series_x)

                    # --- Backtest pair avec params fig√©s
                    # IMPORTANT: cette fonction renvoie (equity, returns, trades)
                    eq_pair, rets_pair = backtest_single_pair_from_config(
                        merged_pf,
                        a1,
                        a2,
                        cfg_params=cfg_params,
                    )

                    # Stocker
                    per_pair_returns[pair_id] = rets_pair
                    per_pair_equity[pair_id] = eq_pair

                    per_pair_info.append({
                        "pair_id": pair_id,
                        "n_bars": int(len(rets_pair)),
                        "sharpe": _compute_sharpe_from_returns(rets_pair, int(pf_periods_per_year)),
                        "mdd": _max_drawdown(eq_pair),
                        "final_equity": float(eq_pair.iloc[-1]) if len(eq_pair) else np.nan,
                        "trades": int(len(rets_pair)) if rets_pair is not None else 0,
                    })

                # --- Portfolio aggregation (equal-weight)
                pf_equity, ret_mat = backtest_portfolio_equal_weight(registry, DATA_PATH)

                st.session_state["pf_last_key"] = pf_key
                st.session_state["pf_equity"] = pf_equity
                st.session_state["pf_ret_mat"] = ret_mat
                st.session_state["pf_pair_stats"] = pd.DataFrame(per_pair_info).sort_values("sharpe", ascending=False)
                st.session_state["pf_pair_equity"] = per_pair_equity

        has_pf = (st.session_state.get("pf_last_key", None) == pf_key and "pf_equity" in st.session_state)

        # =============================
        # TAB 1 ‚Äî OVERVIEW (impact)
        # =============================
        with t_overview:
            st.markdown("### R√©sum√© portefeuille")

            if not has_pf:
                st.info("Clique sur 'Backtester le PF' pour calculer l‚Äôequity portefeuille.")
            else:
                pf_equity = st.session_state["pf_equity"]
                ret_mat = st.session_state["pf_ret_mat"]
                pair_stats = st.session_state["pf_pair_stats"]

                pf_rets = pf_equity.pct_change().fillna(0.0)
                pf_sharpe = _compute_sharpe_from_returns(pf_rets, int(pf_periods_per_year))
                pf_mdd = _max_drawdown(pf_equity)
                pf_final = float(pf_equity.iloc[-1]) if len(pf_equity) else np.nan
                pf_cagr = _cagr_from_equity(pf_equity)

                k1, k2, k3, k4 = st.columns(4)
                k1.metric("Sharpe", f"{pf_sharpe:.3f}")
                k2.metric("Max Drawdown", f"{pf_mdd:.2%}")
                k3.metric("Final Equity", f"{pf_final:.3f}")
                k4.metric("CAGR", f"{pf_cagr:.2%}" if np.isfinite(pf_cagr) else "n/a")

                # Equity chart (main hero)
                fig_pf = go.Figure()
                fig_pf.add_scatter(x=pf_equity.index, y=pf_equity, mode="lines", name="Portfolio Equity")
                fig_pf.update_layout(template="plotly_dark", height=420, margin=dict(l=20, r=20, t=40, b=20))
                st.plotly_chart(fig_pf, width='stretch')

                # ‚ÄúTop pairs‚Äù compact
                st.markdown("### Top contributeurs (par Sharpe paire)")
                st.dataframe(pair_stats[["pair_id", "sharpe", "mdd", "final_equity"]].head(10), width='stretch')

                # Details regroup√©s en expanders
                with st.expander("Voir les returns (en %)"):
                    pf_rets_pct = (pf_rets * 100.0).rename("PF_return_%")

                    a1, a2, a3, a4 = st.columns(4)
                    a1.metric("Mean / bar", f"{pf_rets_pct.mean():.4f}%")
                    a2.metric("Vol / bar", f"{pf_rets_pct.std(ddof=1):.4f}%")
                    a3.metric("Best bar", f"{pf_rets_pct.max():.2f}%")
                    a4.metric("Worst bar", f"{pf_rets_pct.min():.2f}%")

                    rets_table = pd.DataFrame({"return_%": pf_rets_pct.values}, index=pf_rets.index)
                    rets_table.index.name = "datetime"
                    st.dataframe(rets_table.tail(200), width='stretch')

                    fig_rets = px.histogram(rets_table.reset_index(), x="return_%", nbins=60)
                    fig_rets.update_layout(template="plotly_dark", height=320, margin=dict(l=20, r=20, t=40, b=20))
                    st.plotly_chart(fig_rets, width='stretch')

                with st.expander("Voir les contributions (equal-weight)"):
                    n_pairs = max(1, ret_mat.shape[1])
                    contrib_pct = (ret_mat * (1.0 / n_pairs) * 100.0).copy()
                    cum_contrib_pct = contrib_pct.cumsum()

                    fig_contrib = go.Figure()
                    for col in cum_contrib_pct.columns:
                        fig_contrib.add_scatter(
                            x=cum_contrib_pct.index,
                            y=cum_contrib_pct[col],
                            mode="lines",
                            name=str(col),
                        )
                    fig_contrib.update_layout(template="plotly_dark", height=380, margin=dict(l=20, r=20, t=40, b=20))
                    st.plotly_chart(fig_contrib, width='stretch')

        # =============================
        # TAB 2 ‚Äî PAIRES (gestion + drilldown)
        # =============================
        with t_pairs:
            st.markdown("### Paires en portefeuille")
            st.dataframe(reg_flat[show_cols], width='stretch')

            st.markdown("### Drilldown paire")
            pair_choices = [f"{it.get('pair_id')} | {it.get('timeframe', 'UNKNOWN')}" for it in registry]
            chosen = st.selectbox("Choisir une paire", pair_choices, key="pf_detail_select")

            # trouver l‚Äôitem
            item = None
            if chosen:
                pair_id = chosen.split("|")[0].strip()
                timeframe = chosen.split("|")[1].strip() if "|" in chosen else "UNKNOWN"
                for it in registry:
                    if it.get("pair_id") == pair_id and it.get("timeframe", "UNKNOWN") == timeframe:
                        item = it
                        break

            if item is not None:
                # Mini ‚Äúcards‚Äù utiles
                m1, m2, m3, m4 = st.columns(4)
                m1.metric("Robustness", f"{float(item.get('metrics', {}).get('Robustness', np.nan)):.3f}" if item.get(
                    "metrics") else "n/a")
                m2.metric("Sharpe real", f"{float(item.get('metrics', {}).get('Sharpe_real', np.nan)):.3f}" if item.get(
                    "metrics") else "n/a")
                m3.metric("Z-entry", f"{float(item.get('params', {}).get('z_entry', np.nan)):.3f}" if item.get(
                    "params") else "n/a")
                m4.metric("Z-exit",
                          f"{float(item.get('params', {}).get('z_exit', np.nan)):.3f}" if item.get("params") else "n/a")

                # √âquity de la paire si PF d√©j√† calcul√©
                if has_pf and "pf_pair_equity" in st.session_state:
                    per_eq = st.session_state["pf_pair_equity"]
                    if item["pair_id"] in per_eq:
                        st.markdown("#### Equity de la paire")
                        eq_pair = per_eq[item["pair_id"]]
                        fig_p = go.Figure()
                        fig_p.add_scatter(x=eq_pair.index, y=eq_pair, mode="lines", name=item["pair_id"])
                        fig_p.update_layout(template="plotly_dark", height=320, margin=dict(l=20, r=20, t=40, b=20))
                        st.plotly_chart(fig_p, width='stretch')

                with st.expander("Param√®tres (JSON)"):
                    st.json(item.get("params", {}))
                with st.expander("M√©triques d‚Äôoptimisation (JSON)"):
                    st.json(item.get("metrics", {}))

            st.markdown("### Gestion")
            r1, r2 = st.columns([5, 1])
            selected_remove = r1.selectbox("Supprimer une paire", pair_choices, key="pf_remove_select")
            r2.markdown("<div style='height: 28px;'></div>", unsafe_allow_html=True)
            do_remove = r2.button("Supprimer", key="pf_remove_btn", width='stretch')

            if do_remove and selected_remove:
                pair_id = selected_remove.split("|")[0].strip()
                timeframe = selected_remove.split("|")[1].strip() if "|" in selected_remove else "UNKNOWN"
                remove_pair_config(pair_id, timeframe, REGISTRY_PATH)
                st.success(f"Supprim√©: {pair_id} ({timeframe})")
                _rerun()

        # =============================
        # TAB 3 ‚Äî DETAILS (OPTIONNEL)
        # =============================
        with t_adv:
            st.markdown("### D√©tails (optionnel)")
            st.caption("R√©serv√© aux checks plus lourds. √Ä garder ferm√© la plupart du temps.")

            if not has_pf:
                st.info("Lance d‚Äôabord le PF pour afficher les d√©tails.")
            else:
                pf_equity = st.session_state["pf_equity"]
                ret_mat = st.session_state["pf_ret_mat"]

                show_heavy = st.toggle("Afficher les vues d√©taill√©es", value=False, key="pf_show_heavy")

                if show_heavy:
                    st.markdown("#### Matrice de returns (align√©e) ‚Äì tail")
                    st.dataframe(ret_mat.tail(300), width='stretch')

                    st.markdown("#### Returns par paire (en %) ‚Äì tail")
                    st.dataframe((ret_mat * 100.0).tail(300), width='stretch')

                    st.markdown("#### Perf cumul√©e (PF) ‚Äì en %")
                    pf_cum_pct = ((pf_equity / pf_equity.iloc[0]) - 1.0) * 100.0
                    fig_cum = go.Figure()
                    fig_cum.add_scatter(x=pf_cum_pct.index, y=pf_cum_pct, mode="lines", name="Cumulative %")
                    fig_cum.update_layout(template="plotly_dark", height=320, margin=dict(l=20, r=20, t=40, b=20))
                    st.plotly_chart(fig_cum, width='stretch')
                else:
                    st.info("Active le toggle pour afficher les tableaux et graphiques d√©taill√©s.")









